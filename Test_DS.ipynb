{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_DS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayssajeb94/Test_DS/blob/master/Test_DS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MIv8jAMDDZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "#This will ask for permission\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNm9rUogCXhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "712c3c82-1afb-4641-9d8a-acbf6bc9b0f0"
      },
      "source": [
        "#import the necessary libraries\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn import cluster\n",
        "from scipy.spatial.distance import cdist\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "#initialize the variables\n",
        "distortions = []  #It is calculated as the average of the squared distances from the cluster centers of the respective clusters.\n",
        "inertias = [] #It is the sum of squared distances of samples to their closest cluster center.\n",
        "mapping1 = {} \n",
        "mapping2 = {} \n",
        "K = range(1,10) #Limit the number of groups between 1 and 10\n",
        "\n",
        "#function to read dataset in first time form json file, and then convert it into dataframe.\n",
        "def readData():   \n",
        "    \n",
        "    with open(file) as f:\n",
        "         d = json.load(f)\n",
        "         df = pd.DataFrame.from_dict(d, orient='columns')\n",
        "         return df\n",
        "\n",
        "#function to remove the warning by using the catch_warnings context handler:\n",
        "def fxn():\n",
        "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    fxn()\n",
        "    \n",
        "    \n",
        "# =============================================================================\n",
        "# main function\n",
        "# Perform a clustering based on either the location or characteristics of \n",
        "# bike stations.\n",
        "# =============================================================================\n",
        "\n",
        "#read json file\n",
        "print(\"1.==  Read data\")\n",
        "file = input(\"Enter your Json file:\")\n",
        "#file = 'Brisbane_CityBike.json'\n",
        "data = readData()\n",
        "newdf = data[['latitude','longitude']]\n",
        "print(newdf)\n",
        "\n",
        "\n",
        "#•Detrmine the optimal nubmer of k\n",
        "print(\"2.choise of groupe number\")\n",
        "for k in K: \n",
        "    kmeanModel = cluster.KMeans(n_clusters=k).fit(newdf) \n",
        "    kmeanModel.fit(newdf)     \n",
        "      \n",
        "    distortions.append(sum(np.min(cdist(newdf, kmeanModel.cluster_centers_, \n",
        "                      'euclidean'),axias=1)) / newdf.shape[0]) \n",
        "    inertias.append(kmeanModel.inertia_) \n",
        "  \n",
        "    mapping1[k] = sum(np.min(cdist(newdf, kmeanModel.cluster_centers_, \n",
        "                 'euclidean'),axis=1)) / newdf.shape[0] \n",
        "    mapping2[k] = kmeanModel.inertia_ \n",
        "\n",
        "#To determine the optimal number of clusters, we have to select the value of k at the “elbow” ie the point\n",
        "#after which the distortion/inertia start decreasing in a linear fashion\n",
        "\n",
        "plt.plot(K, distortions, 'bx-') \n",
        "plt.xlabel('number of cluster') \n",
        "plt.ylabel('Distortion') \n",
        "plt.title('The Elbow Method using Distortion') \n",
        "plt.show() \n",
        "\n",
        "#according to the elbow method, we can know the best\n",
        "#number of groups to choose.    \n",
        "n_cluster = int(input(\"enter the appropriate number of groups:\"))\n",
        "\n",
        "fxn()\n",
        "\n",
        "#clustering\n",
        "print(\"3.clustering Data\")\n",
        "kmeans = cluster.KMeans(n_clusters=n_cluster)\n",
        "kmeans.fit(newdf)\n",
        "#index sorted groups\n",
        "idk = np.argsort(kmeans.labels_)\n",
        "#displaying observations and their groups\n",
        "output=newdf.iloc[idk]\n",
        "output['groupe']=kmeans.labels_[idk]\n",
        "output['number']=data['number'][idk]\n",
        "output['name']=data['name'][idk]\n",
        "output['address']=data['address'][idk]\n",
        "output['longitude']=data['longitude'][idk]\n",
        "output['latitude']=data['latitude'][idk]\n",
        "\n",
        "print(\"3.export Data\")\n",
        "#write result to csv files\n",
        "output.to_csv('Groupes.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.==  Read data\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}